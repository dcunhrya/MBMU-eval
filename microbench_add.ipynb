{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5cc7e3",
   "metadata": {},
   "source": [
    "## TSV Schema\n",
    "Things to include:\n",
    "- index (int)\n",
    "- image_path (str)\n",
    "- question (str)\n",
    "- options (JSON list of str)\n",
    "- answer (str)\n",
    "- (optional) hint, category, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7722e77",
   "metadata": {},
   "source": [
    "### What uBench Has\n",
    "- image\n",
    "- questions (contains question and options and snwer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb98476",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b024ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "import os, json, argparse\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from vlmeval.dataset.image_base import ImageBaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41468cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _letters(n: int):\n",
    "    assert 1 <= n <= 26, \"This template supports up to 26 options.\"\n",
    "    return list(string.ascii_uppercase[:n])  # ['A', ... 'Z'][:n]\n",
    "\n",
    "def _parse_letter(text: str, num_opts: int) -> str:\n",
    "    \"\"\"Strict A..(A+num_opts-1) parser; returns 'INVALID' if no single-letter answer is found.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"INVALID\"\n",
    "    t = text.strip().upper()\n",
    "    valid = set(_letters(num_opts))\n",
    "    if len(t) == 1 and t in valid:\n",
    "        return t\n",
    "    # tolerate explanations like \"Answer: H ...\"\n",
    "    for ch in reversed(t):\n",
    "        if ch in valid:\n",
    "            return ch\n",
    "    return \"INVALID\"\n",
    "\n",
    "class MicroBenchTSV(ImageBaseDataset):\n",
    "    \"\"\"\n",
    "    Minimal TSV-backed MCQ dataset for VLMEvalKit.\n",
    "\n",
    "    TSV columns (required):\n",
    "      - index (int)\n",
    "      - image_path (str)          # single path or multiple paths joined by ';'\n",
    "      - question (str)\n",
    "      - options (JSON list[str])  # e.g., [\"None of the above\", \"Actin\", ...]\n",
    "      - answer (str)              # single letter \"A\"..\"Z\"\n",
    "\n",
    "    Optional:\n",
    "      - hint (str)\n",
    "      - category (str)\n",
    "      - split (str)\n",
    "\n",
    "    Notes:\n",
    "    - If image_path contains multiple paths separated by ';', we will emit multiple image messages.\n",
    "    - We keep prompting very strict: model must output a single letter.\n",
    "    \"\"\"\n",
    "    TYPE = 'MCQ'\n",
    "    NAME = 'MICROBENCH_TSV'\n",
    "\n",
    "    # data_file is a path RELATIVE to $LMUData (default: ~/LMUData)\n",
    "    # Example: data_file='microbench/uBench_classification_10.tsv'\n",
    "    def __init__(self, data_file: str, **kwargs):\n",
    "        super().__init__(data_file=data_file, **kwargs)\n",
    "        # Load TSV into self.data (a pandas DataFrame)\n",
    "        # ImageBaseDataset will resolve $LMUData for us.\n",
    "        tsv_path = self.data_file\n",
    "        if not os.path.isabs(tsv_path):\n",
    "            # ImageBaseDataset may already resolve; if not, try LMUData env\n",
    "            lmu_root = os.environ.get('LMUData', os.path.expanduser('~/LMUData'))\n",
    "            tsv_path = os.path.join(lmu_root, self.data_file)\n",
    "        self.data = pd.read_csv(tsv_path, sep='\\t')\n",
    "\n",
    "        required = ['index', 'image_path', 'question', 'options', 'answer']\n",
    "        missing = [c for c in required if c not in self.data.columns]\n",
    "        if missing:\n",
    "            raise KeyError(f\"TSV missing required columns: {missing}\")\n",
    "\n",
    "    def build_prompt(self, line):\n",
    "        \"\"\"Return VLMEvalKit multimodal messages: [{'type': 'image'|'text', 'value': ...}, ...]\"\"\"\n",
    "        row = self.data.iloc[line] if isinstance(line, int) else line\n",
    "\n",
    "        # Build image message(s)\n",
    "        img_field = str(row['image_path'])\n",
    "        img_paths = [p for p in img_field.split(';') if p.strip()]  # support multi-image\n",
    "        # Keep as absolute if already absolute; else try to resolve relative to LMUData\n",
    "        lmu_root = os.environ.get('LMUData', os.path.expanduser('~/LMUData'))\n",
    "        def resolve(p):\n",
    "            return p if os.path.isabs(p) else os.path.join(lmu_root, p)\n",
    "        image_msgs = [dict(type='image', value=resolve(p)) for p in img_paths]\n",
    "\n",
    "        # Options\n",
    "        opts = row['options']\n",
    "        if isinstance(opts, str):\n",
    "            opts = json.loads(opts)\n",
    "        letters = _letters(len(opts))\n",
    "        options_txt = \"\\n\".join(f\"{L}. {t}\" for L, t in zip(letters, opts))\n",
    "\n",
    "        # Optional hint for context (if present)\n",
    "        hint = str(row['hint']).strip() if 'hint' in self.data.columns and not pd.isna(row['hint']) else \"\"\n",
    "        hint_txt = (hint + \"\\n\") if hint else \"\"\n",
    "\n",
    "        prompt = (\n",
    "            f\"{hint_txt}{row['question']}\\n\"\n",
    "            f\"Options:\\n{options_txt}\\n\"\n",
    "            f\"Answer with a single letter ({letters[0]}â€“{letters[-1]}) only.\"\n",
    "        )\n",
    "        return [*image_msgs, dict(type='text', value=prompt)]\n",
    "\n",
    "    def evaluate(self, eval_file, **kwargs):\n",
    "        \"\"\"\n",
    "        Expect model predictions saved by VLMEvalKit under eval_file with at least:\n",
    "        - prediction (raw model text output)\n",
    "        - options (copied from TSV or rejoined) for dynamic parser range\n",
    "        - answer (gold letter)\n",
    "        We compute accuracy and invalid rate.\n",
    "        \"\"\"\n",
    "        df = self.load(eval_file)   # helper from ImageBaseDataset to read predictions Excel/CSV\n",
    "\n",
    "        # Make sure we can get num options per-row; fall back to TSV if missing\n",
    "        if 'options' not in df.columns:\n",
    "            # join with original TSV by 'index'\n",
    "            df = df.merge(self.data[['index', 'options']], on='index', how='left', suffixes=('', '_tsv'))\n",
    "\n",
    "        def _num_opts(opt_field):\n",
    "            try:\n",
    "                return len(json.loads(opt_field)) if isinstance(opt_field, str) else len(opt_field)\n",
    "            except Exception:\n",
    "                return 4\n",
    "\n",
    "        num_opts = df['options'].map(_num_opts)\n",
    "\n",
    "        pred = [\n",
    "            _parse_letter(pred_text, n)\n",
    "            for pred_text, n in zip(df['prediction'], num_opts)\n",
    "        ]\n",
    "        gold = [str(a).strip().upper() for a in df['answer']]\n",
    "\n",
    "        import numpy as np\n",
    "        pred = np.array(pred, dtype=object)\n",
    "        gold = np.array(gold, dtype=object)\n",
    "        valid_mask = pred != 'INVALID'\n",
    "\n",
    "        acc = float((pred == gold).mean())\n",
    "        invalid_rate = float((~valid_mask).mean())\n",
    "\n",
    "        return {\n",
    "            'accuracy': [acc],\n",
    "            'invalid_rate': [invalid_rate]\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
